{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "87c5f1ec",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a608c17b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-05T22:04:37.870918Z",
     "start_time": "2022-04-05T22:04:37.867257Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import numpy as np\n",
    "import re\n",
    "import sqlite3\n",
    "\n",
    "from sqlalchemy import create_engine\n",
    "from datetime   import datetime\n",
    "from bs4        import BeautifulSoup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef22c851",
   "metadata": {},
   "source": [
    "### Data Collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ce58ba05",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-05T22:04:40.304828Z",
     "start_time": "2022-04-05T22:04:38.322615Z"
    }
   },
   "outputs": [],
   "source": [
    "# parameters\n",
    "headers = {'User-Agent': 'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/44.0.2403.157 Safari/537.36'}\n",
    "\n",
    "# url\n",
    "url = 'https://www2.hm.com/en_us/men/products/jeans.html?page-size=108'\n",
    "\n",
    "# request do url\n",
    "page = requests.get(url, headers=headers)\n",
    "\n",
    "# beautiful soup object\n",
    "soup = BeautifulSoup(page.text, 'html.parser')\n",
    "\n",
    "# ========================= Product Data ========================= #\n",
    "products = soup.find('ul', class_= 'products-listing small')\n",
    "product_list = products.find_all('article',class_= 'hm-product-item')\n",
    "\n",
    "# product id\n",
    "product_id = [p.get('data-articlecode') for p in product_list]\n",
    "\n",
    "# product category\n",
    "product_category = [p.get('data-category') for p in product_list]\n",
    "\n",
    "data = pd.DataFrame([product_id, product_category]).T\n",
    "data.columns = ['product_id', 'product_category']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45810279",
   "metadata": {},
   "source": [
    "### Data Collection by Product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0ba5570b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-05T22:11:12.468124Z",
     "start_time": "2022-04-05T22:04:40.515947Z"
    }
   },
   "outputs": [],
   "source": [
    "# unique columns for all products\n",
    "aux = []\n",
    "\n",
    "cols = ['Art. No.','Composition']\n",
    "df_pattern = pd.DataFrame(columns=cols)\n",
    "\n",
    "# empty dataframe\n",
    "df_compositions = pd.DataFrame()\n",
    "\n",
    "for i in range(len(data)):\n",
    "    # API Requests\n",
    "    url = 'https://www2.hm.com/en_us/productpage.' + data.loc[i, 'product_id'] + '.html'\n",
    "    #url = 'https://www2.hm.com/en_us/productpage.' + '0979945001' + '.html'\n",
    "    \n",
    "    page = requests.get(url, headers=headers)\n",
    "    \n",
    "    # Beautiful Soup object\n",
    "    soup = BeautifulSoup(page.text, 'html.parser')\n",
    "    \n",
    "    ################### df_color ###################\n",
    "    product_list = soup.find_all('a', class_='filter-option miniature active') + soup.find_all('a', class_='filter-option miniature')\n",
    "    color_name = [p.get('data-color') for p in product_list]\n",
    "    \n",
    "    # product id\n",
    "    product_id = [p.get('data-articlecode') for p in product_list]\n",
    "    \n",
    "    df_color = pd.DataFrame([product_id, color_name]).T\n",
    "    df_color.columns = ['product_id', 'color_name']\n",
    "    \n",
    "    for j in range(len(df_color)):\n",
    "        # API Requests\n",
    "        url = 'https://www2.hm.com/en_us/productpage.' + df_color.loc[j, 'product_id'] + '.html'\n",
    "\n",
    "        page = requests.get(url, headers=headers)\n",
    "        \n",
    "        # Beautiful Soup object\n",
    "        soup = BeautifulSoup(page.text, 'html.parser')\n",
    "        \n",
    "        # product name\n",
    "        product_name = soup.find_all('h1', class_ = 'primary product-item-headline')\n",
    "        product_name = product_name[0].get_text()\n",
    "        \n",
    "        # product price\n",
    "        product_price = soup.find_all('div', class_ = 'primary-row product-item-price')\n",
    "        product_price = re.findall(r'\\d+\\.?\\d+', product_price[0].get_text())[0]\n",
    "\n",
    "        ################### composition ################\n",
    "          \n",
    "        product_composition_list = soup.find_all('div', class_= 'details-attributes-list-item')\n",
    "        product_composition = [list(filter(None, p.get_text().split('\\n'))) for p in product_composition_list]\n",
    "        \n",
    "        if product_composition != []:\n",
    "            # reframe\n",
    "            df_composition = pd.DataFrame(product_composition).T\n",
    "            df_composition.columns = df_composition.iloc[0]\n",
    "            df_composition = df_composition[df_composition['Composition'].notnull()]\n",
    "\n",
    "            df_composition = df_composition[['Composition', 'Art. No.']]\n",
    "\n",
    "            # delete first row and NA\n",
    "            df_composition = df_composition.iloc[1:].fillna(method='ffill')\n",
    "            df_composition = df_composition.iloc[:2]\n",
    "\n",
    "            # remove pocket lining, shell and lining\n",
    "            df_composition['Composition'] = df_composition['Composition'].str.replace('Pocket lining: ', '', regex=True)\n",
    "            df_composition['Composition'] = df_composition['Composition'].str.replace('Shell: ', '', regex=True)\n",
    "            df_composition['Composition'] = df_composition['Composition'].str.replace('Lining: ', '', regex=True)\n",
    "\n",
    "            # renaming and organizing columns\n",
    "            df_composition = df_composition[['Art. No.', 'Composition']]\n",
    "            df_composition.columns = ['product_id', 'composition']\n",
    "            \n",
    "            df_composition['product_name'] = product_name\n",
    "            df_composition['product_price'] = product_price\n",
    "\n",
    "            # keep new columns if t shows up\n",
    "            aux = aux + df_composition.columns.tolist()\n",
    "\n",
    "            # merge\n",
    "            df_composition = pd.merge(df_composition, df_color, how='left', on='product_id')\n",
    "\n",
    "            # all products\n",
    "            df_compositions = pd.concat([df_compositions, df_composition], axis=0)\n",
    "        else:\n",
    "            None\n",
    "    \n",
    "df_compositions['style_id'] = df_compositions['product_id'].apply(lambda x: x[:-3])\n",
    "df_compositions['color_id'] = df_compositions['product_id'].apply(lambda x: x[-3:])\n",
    "\n",
    "# scrapy datetime\n",
    "df_compositions['scrapy-datetime'] = datetime.now().strftime('%Y-%m-%d %H:%M:%S')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9cb3cdf",
   "metadata": {},
   "source": [
    "### Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a7048e57",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-05T22:11:12.549061Z",
     "start_time": "2022-04-05T22:11:12.470088Z"
    }
   },
   "outputs": [],
   "source": [
    "# product_id\n",
    "df_data = df_compositions.dropna(subset=['product_id'])\n",
    "\n",
    "# product_name\n",
    "df_data['product_name'] = df_data['product_name'].str.replace('\\n', '')\n",
    "df_data['product_name'] = df_data['product_name'].str.replace('\\t', '')\n",
    "df_data['product_name'] = df_data['product_name'].str.replace('  ', '')\n",
    "df_data['product_name'] = df_data['product_name'].str.replace(' ', '_').str.lower()\n",
    "\n",
    "# product price\n",
    "df_data['product_price'] = df_data['product_price'].astype(float)\n",
    "\n",
    "# product_color\n",
    "df_data['color_name'] = df_data['color_name'].str.replace(' ', '_').str.lower()\n",
    "\n",
    "# renaming columns\n",
    "df_data = df_data.rename(columns = {'Composition':'composition','scrapy-datetime':'scrapy_datetime'})\n",
    "\n",
    "# break composition by comma\n",
    "df1 = df_data['composition'].str.split(',', expand=True).reset_index(drop=True)\n",
    "\n",
    "# ================== cotton | polyester | elastomultiester | spandex | modal |\n",
    "df_ref = pd.DataFrame(index=np.arange(len(df_data)), columns=['cotton', 'polyester', 'spandex', 'modal',\n",
    "                                                             'elastomultiester'])\n",
    "\n",
    "# ==================  cotton\n",
    "df_cotton_0 = df1.loc[df1[0].str.contains('Cotton', na=True), 0]\n",
    "df_cotton_0.name = 'cotton'\n",
    "\n",
    "df_cotton_1 = df1.loc[df1[1].str.contains('Cotton', na=True), 1]\n",
    "df_cotton_1.name = 'cotton'\n",
    "\n",
    "# combine\n",
    "df_cotton = df_cotton_0.combine_first(df_cotton_1)\n",
    "\n",
    "df_ref = pd.concat([df_ref, df_cotton], axis=1)\n",
    "df_ref = df_ref.iloc[:, ~df_ref.columns.duplicated(keep='last')]\n",
    "\n",
    "# ================== polyester\n",
    "df_polyester_0 = df1.loc[df1[0].str.contains('Polyester', na=True), 0]\n",
    "df_polyester_0.name = 'polyester'\n",
    "\n",
    "df_polyester_1 = df1.loc[df1[1].str.contains('Polyester', na=True), 1]\n",
    "df_polyester_1.name = 'polyester'\n",
    "\n",
    "# combine\n",
    "df_polyester = df_polyester_0.combine_first(df_polyester_1)\n",
    "\n",
    "df_ref = pd.concat([df_ref, df_polyester], axis=1)\n",
    "df_ref = df_ref.iloc[:, ~df_ref.columns.duplicated(keep='last')]\n",
    "\n",
    "# ================== spandex\n",
    "df_spandex_1 = df1.loc[df1[1].str.contains('Spandex', na=True), 1]\n",
    "df_spandex_1.name = 'spandex'\n",
    "\n",
    "df_spandex_2 = df1.loc[df1[2].str.contains('Spandex', na=True), 2]\n",
    "df_spandex_2.name = 'spandex'\n",
    "\n",
    "df_spandex_3 = df1.loc[df1[3].str.contains('Spandex', na=True), 3]\n",
    "df_spandex_3.name = 'spandex'\n",
    "\n",
    "\n",
    "# combine\n",
    "df_spandex_c2 = df_spandex_1.combine_first(df_spandex_2)\n",
    "df_spandex = df_spandex_c2.combine_first(df_spandex_3)\n",
    "\n",
    "df_ref = pd.concat([df_ref, df_spandex], axis=1)\n",
    "df_ref = df_ref.iloc[:, ~df_ref.columns.duplicated(keep='last')]\n",
    "\n",
    "# ================== elastomultiester\n",
    "df_elastomultiester = df1.loc[df1[1].str.contains('Elastomultiester', na=True), 1]\n",
    "df_elastomultiester.name = 'elastomultiester'\n",
    "\n",
    "# combine \n",
    "df_ref = pd.concat([df_ref, df_elastomultiester], axis=1)\n",
    "df_ref = df_ref.iloc[:, ~df_ref.columns.duplicated(keep='last')]\n",
    "\n",
    "# ================== modal\n",
    "df_modal = df1.loc[df1[2].str.contains('Modal', na=True), 2]\n",
    "df_modal.name = 'modal'\n",
    "\n",
    "# combine\n",
    "df_ref = pd.concat([df_ref, df_modal], axis=1)\n",
    "df_ref = df_ref.iloc[:, ~df_ref.columns.duplicated(keep='last')]\n",
    "\n",
    "# join of combine with product_id\n",
    "df_aux = pd.concat([df_data['product_id'].reset_index(drop=True), df_ref], axis=1)\n",
    "\n",
    "# breaking composition\n",
    "df_aux['cotton'] = df_aux['cotton'].apply(lambda x: int(re.search('Cotton (\\d*)', x).group(1)) / 100 if (pd.notnull(x)) and ('Cotton' in x) else 0)\n",
    "df_aux['spandex'] = df_aux['spandex'].apply(lambda x: int(re.search('Spandex (\\d*)', x).group(1)) / 100 if pd.notnull(x) and ('Spandex' in x) else 0)\n",
    "df_aux['polyester'] = df_aux['polyester'].apply(lambda x: int(re.search('Polyester (\\d*)', x).group(1)) / 100 if pd.notnull(x) and ('Polyester' in x) else 0)\n",
    "df_aux['modal'] = df_aux['modal'].apply(lambda x: int(re.search('Modal (\\d*)', x).group(1)) / 100 if pd.notnull(x) and ('Modal' in x) else 0)\n",
    "df_aux['elastomultiester'] = df_aux['elastomultiester'].apply(lambda x: int(re.search('Elastomultiester (\\d*)', x).group(1)) / 100 if pd.notnull(x) and ('Elastomultiester' in x) else 0)\n",
    "\n",
    "\n",
    "# final join\n",
    "df_aux = df_aux.groupby('product_id').max().reset_index()\n",
    "df_data = pd.merge(df_data, df_aux, on='product_id', how='left')\n",
    "\n",
    "# drop columns\n",
    "df_data = df_data.drop(columns = 'composition', axis=1)\n",
    "\n",
    "# drop duplicates\n",
    "df_data = df_data.drop_duplicates().reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f747cece",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-05T06:25:38.849709Z",
     "start_time": "2022-04-05T06:25:38.827660Z"
    }
   },
   "source": [
    "### Data Insert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a1045264",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-05T22:11:12.556290Z",
     "start_time": "2022-04-05T22:11:12.551678Z"
    }
   },
   "outputs": [],
   "source": [
    "data_insert = df_data[[\n",
    "    'product_id',\n",
    "    'style_id',\n",
    "    'color_id',\n",
    "    'product_name',\n",
    "    'color_name',\n",
    "    'product_price',\n",
    "    'cotton',\n",
    "    'polyester',\n",
    "    'spandex',\n",
    "    'modal',\n",
    "    'elastomultiester',\n",
    "    'scrapy_datetime'\n",
    "]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f2a5ec7a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-05T22:11:12.561182Z",
     "start_time": "2022-04-05T22:11:12.558199Z"
    }
   },
   "outputs": [],
   "source": [
    "#query_showroom_schema = \"\"\"\n",
    "#    CREATE TABLE vitrine(\n",
    "#        'product_id'            TEXT,\n",
    "#        'style_id'              TEXT,\n",
    "#        'color_id'              TEXT,\n",
    "#        'product_name'          TEXT,\n",
    "#        'color_name'            TEXT,\n",
    "#        'product_price'         REAL,\n",
    "#        'cotton'                REAL,\n",
    "#        'polyester'             REAL,\n",
    "#        'spandex'               REAL,\n",
    "#        'modal'                 REAL,\n",
    "#        'elastomultiester'      REAL,\n",
    "#        'scrapy_datetime'       TEXT\n",
    "#    )\n",
    "#\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "488ec302",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-05T22:11:12.566671Z",
     "start_time": "2022-04-05T22:11:12.563413Z"
    }
   },
   "outputs": [],
   "source": [
    "## create table\n",
    "#conn = sqlite3.connect('database_hm.sqlite')\n",
    "#cursor = conn.execute(query_showroom_schema)\n",
    "#conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ae4e03be",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-05T22:11:12.593837Z",
     "start_time": "2022-04-05T22:11:12.568714Z"
    }
   },
   "outputs": [],
   "source": [
    "# create database connection\n",
    "conn = create_engine('sqlite:///database_hm.sqlite', echo=False)\n",
    "\n",
    "\n",
    "# data insert\n",
    "data_insert.to_sql('vitrine', con=conn, if_exists='append', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
